{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP FOR A BINARY CLASSIFICATION PROBLEM: Physical or Non physical matrix?\n",
    "\n",
    "The goal is to descriminate between matrices that are physical, i.e. that represent a quantum state, or matrices that are not physical. In this first approach I use matrix with all the same size, associated to an Hilbert Space Dimension of 4: 4x4 matrices, i.e. 16 complex elements in each matrix. \n",
    "I generated 300 physical and 300 non physical matrices in a MATLAB code (Dataset_creation.m). A physical matrix, also called Density matrix, must satisfy three requirements: it must be positive definite, hermitian, with trace equal to 1. In order to obtain this, in the MATLAB code, I first randomly generate 4x4 complex matrices. Each element of these matrices has real and imaginary part randomly extracted from a uniform distribution in the interval (-1,1). Then, I make matrices symmetric, with real diagonal values. To obtain positive definite matrices I use the Modified Cholesky Factorization. I found on internet a MATLAB code to implement this factorization (modchol_ldlt.m), for this I chose to generate matrices in MATLAB. Finally, I make matrices hermitian, and I normalize them to obtain trace equal to 1.\n",
    "I also created non physical matrices. From these we can found: 75 randomly generated complex matrices, 75 positive definite complex matrices, 75 positive definite and hermitian matrices and 75 positive definite matrices with trace equal to 1. \n",
    "I reshape each generated matrix in a row vector of shape (1x16). From the MATLAB code I saved real and imaginary part of Physical and Non Physical matrices in four '.txt' files. Each row of files represents a different matrix, the columns are matrices' elements (my features).\n",
    "I will build the complete dataset in this code. \n",
    "\n",
    "I choose label 0 to classify Physical matrices, label 1 to classify Non Physical matrices.\n",
    "\n",
    "I will implement a Multilayer Perceptron to solve the classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET CREATION\n",
    "\n",
    "To create the dataset, first I import the generated data in MATLAB. I recombine the corresponding real and imaginary part of each element of each matrix by store them in two matrix: Physical_mat and NonPhysical_mat. Each row of Physical_mat (NonPhysical_mat) represents a specific physical (non physical) matrix, while columns are the features (complex elements of matrices). Physical_mat and NonPhysical_mat have dimensions (300,16).\n",
    "Then, I concatenate target vectors to the two matrices and I create the final dataset. The Dataset matrix has dimension (600,17) where 600 is the number of generate matrices (300 physical + 300 non physical), the first 16 columns have features while the last column has target labels (0 or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimension :  (600, 17)\n",
      "features size:  (600, 16) , target size:  (600,)\n"
     ]
    }
   ],
   "source": [
    "#import data generated in MATLAB\n",
    "physical_real=np.loadtxt(r'/Users/noemitagliavacche/Documents/PhD/COURSES/MACHINE_LEARNING/Exam/MATLAB_dataset_creation/300_Physical_matrices_Dim=4_RealPart.txt')\n",
    "Non_physical_real=np.loadtxt(r'/Users/noemitagliavacche/Documents/PhD/COURSES/MACHINE_LEARNING/Exam/MATLAB_dataset_creation/300_Non_Physical_matrices_Dim=4_RealPart.txt')\n",
    "physical_imag=np.loadtxt(r'/Users/noemitagliavacche/Documents/PhD/COURSES/MACHINE_LEARNING/Exam/MATLAB_dataset_creation/300_Physical_matrices_Dim=4_ImagPart.txt')\n",
    "Non_physical_imag=np.loadtxt(r'/Users/noemitagliavacche/Documents/PhD/COURSES/MACHINE_LEARNING/Exam/MATLAB_dataset_creation/300_Non_Physical_matrices_Dim=4_ImagPart.txt')\n",
    "#print(physical_real.shape, Non_physical_real.shape)\n",
    "\n",
    "################ TO CREATE THE DATASET #############\n",
    "Physical_mat=[]\n",
    "NonPhysical_mat=[]\n",
    "\n",
    "for i in range(physical_real.shape[0]):\n",
    "    for j in range(physical_real.shape[1]):\n",
    "        Physical_mat=np.append(Physical_mat,complex(physical_real[i][j],physical_imag[i][j]))\n",
    "        NonPhysical_mat=np.append(NonPhysical_mat,complex(Non_physical_real[i][j],Non_physical_imag[i][j]))\n",
    "        \n",
    "Physical_mat=np.reshape(Physical_mat, (physical_real.shape[0],physical_real.shape[1]))    \n",
    "NonPhysical_mat=np.reshape(NonPhysical_mat, (physical_real.shape[0],physical_real.shape[1]))\n",
    "#print(Physical_mat.shape, NonPhysical_mat.shape)\n",
    "\n",
    "#Classifier: 0-> Physical matrix, 1-> Non physical matrix\n",
    "target_Physical=np.zeros((Physical_mat.shape[0],1),dtype=int)\n",
    "target_NonPhysical=np.ones((Physical_mat.shape[0],1),dtype=int)\n",
    "\n",
    "\n",
    "Physical_data=np.concatenate((Physical_mat,target_Physical),axis=1)\n",
    "NonPhysical_data=np.concatenate((NonPhysical_mat,target_NonPhysical),axis=1)\n",
    "\n",
    "dataset=np.concatenate((Physical_data,NonPhysical_data),axis=0)\n",
    "print(\"Dataset dimension : \", dataset.shape)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "features=dataset[:,:-1]\n",
    "target=[]\n",
    "for elements in dataset[:,dataset.shape[1]-1]:\n",
    "    target=np.append(target, int(elements.real))\n",
    "\n",
    "target=target.T\n",
    "print(\"features size: \", features.shape, \", target size: \", target.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can split the dataset in train and validation set, with a ratio of 2:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (402, 16) , X_val:  (198, 16) , Y_train:  (402,) , Y_val:  (198,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(features, target, test_size=0.33, shuffle=False)\n",
    "print(\"X_train: \",X_train.shape,\", X_val: \" ,X_val.shape, \", Y_train: \", Y_train.shape, \", Y_val: \",Y_val.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING THE MLP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# keras imports\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
