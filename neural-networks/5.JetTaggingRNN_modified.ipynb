{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRBSuEXiD0iD"
      },
      "source": [
        "# Training a Jet Tagging with **Recurrent Neural Network** \n",
        "\n",
        "---\n",
        "In this notebook, we perform a Jet identification task using a multiclass classifier with a GRU unit.\n",
        "Gated Recurrent Units are one kind of RNNs. \n",
        "\n",
        "The problem consists in identifying a given jet as a quark, a gluon, a W, a Z, or a top,\n",
        "based on a jet image, i.e., a 2D histogram of the transverse momentum ($p_T$) deposited in each of 100x100\n",
        "bins of a square window of the ($\\eta$, $\\phi$) plane, centered along the jet axis.\n",
        "\n",
        "For details on the physics problem, see https://arxiv.org/pdf/1804.06913.pdf \n",
        "\n",
        "For details on the dataset, see Notebook1\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "N4Q_0fW_D0iF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJLWXkYnD0iF"
      },
      "source": [
        "# Preparation of the training and validation samples\n",
        "\n",
        "---\n",
        "In order to import the dataset, we now\n",
        "- clone the dataset repository (to import the data in Colab)\n",
        "- load the h5 files in the data/ repository\n",
        "- extract the data we need: a target and jetImage \n",
        "\n",
        "To type shell commands, we start the command line with !\n",
        "\n",
        "nb, if you are running locally you can skip the step below and change the paths later to point to the folder with your previous download of the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZmN3yf7bD0iG",
        "outputId": "01bb7f49-8ea9-4f27-81b7-118a1dbecd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  333M    0  333M    0     0  14.8M      0 --:--:--  0:00:22 --:--:-- 17.8M\n",
            "Data-MLtutorial/\n",
            "Data-MLtutorial/JetDataset/\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_0_10000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_10000_20000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_40000_50000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_50000_60000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_60000_70000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_70000_80000.h5\n",
            "Data-MLtutorial/JetDataset/jetImage_7_100p_80000_90000.h5\n",
            "jetImage_7_100p_0_10000.h5\tjetImage_7_100p_50000_60000.h5\n",
            "jetImage_7_100p_10000_20000.h5\tjetImage_7_100p_60000_70000.h5\n",
            "jetImage_7_100p_30000_40000.h5\tjetImage_7_100p_70000_80000.h5\n",
            "jetImage_7_100p_40000_50000.h5\tjetImage_7_100p_80000_90000.h5\n"
          ]
        }
      ],
      "source": [
        "! curl https://cernbox.cern.ch/s/6Ec5pGFEpFWeH6S/download -o Data-MLtutorial.tar.gz\n",
        "! tar -xvzf Data-MLtutorial.tar.gz \n",
        "! ls Data-MLtutorial/JetDataset/\n",
        "! rm Data-MLtutorial.tar.gz "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fZ7vCwacD0iG",
        "outputId": "63d27dd5-8cc8-4384-c9a5-c96135319d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5\n",
            "Appending Data-MLtutorial/JetDataset/jetImage_7_100p_60000_70000.h5\n",
            "Appending Data-MLtutorial/JetDataset/jetImage_7_100p_50000_60000.h5\n",
            "Appending Data-MLtutorial/JetDataset/jetImage_7_100p_10000_20000.h5\n",
            "Appending Data-MLtutorial/JetDataset/jetImage_7_100p_0_10000.h5\n",
            "(50000, 5) (50000, 100, 16)\n"
          ]
        }
      ],
      "source": [
        "target = np.array([])\n",
        "jetList = np.array([])\n",
        "# we cannot load all data on Colab. So we just take a few files\n",
        "datafiles = ['Data-MLtutorial/JetDataset/jetImage_7_100p_30000_40000.h5',\n",
        "             'Data-MLtutorial/JetDataset/jetImage_7_100p_60000_70000.h5',\n",
        "             'Data-MLtutorial/JetDataset/jetImage_7_100p_50000_60000.h5',\n",
        "             'Data-MLtutorial/JetDataset/jetImage_7_100p_10000_20000.h5',\n",
        "             'Data-MLtutorial/JetDataset/jetImage_7_100p_0_10000.h5']\n",
        "# if you are running locallt, you can use the full dataset doing\n",
        "# for fileIN in glob.glob(\"tutorials/HiggsSchool/data/*h5\"):\n",
        "for fileIN in datafiles:\n",
        "    print(\"Appending %s\" %fileIN)\n",
        "    f = h5py.File(fileIN)\n",
        "    myJetList = np.array(f.get(\"jetConstituentList\"))\n",
        "    mytarget = np.array(f.get('jets')[0:,-6:-1])\n",
        "    jetList = np.concatenate([jetList, myJetList], axis=0) if jetList.size else myJetList\n",
        "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
        "    del myJetList, mytarget\n",
        "    f.close()\n",
        "print(target.shape, jetList.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmsqnYThD0iH"
      },
      "source": [
        "The dataset consists of 50000 with up to 100 particles in each jet. These 100 particles have been used to fill the 100x100 jet images.\n",
        "\n",
        "---\n",
        "\n",
        "We now shuffle the data, splitting them into a training and a validation dataset with 2:1 ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vG-frxjvD0iH",
        "outputId": "c019d6d4-fa6e-47f6-dad4-093eefd4d6ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33500, 100, 16) (16500, 100, 16) (33500, 5) (16500, 5)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(jetList, target, test_size=0.33)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
        "del jetList, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from types import new_class\n",
        "#normalizzo le features\n",
        "\n",
        "#faccio il reshape per passare da un dataset di size (nj,np,nf)->(nj*np,nf)\n",
        "nj=X_train.shape[0]\n",
        "n_p=X_train.shape[1]\n",
        "nf=X_train.shape[2]\n",
        "n_new=nj*n_p\n",
        "#print(type(X_train))\n",
        "#print(type(n_new), type(nf))\n",
        "new_train=np.reshape(X_train,(n_new,nf))\n",
        "print(new_train.shape, n_new)"
      ],
      "metadata": {
        "id": "obnkXl0HD3Q8",
        "outputId": "3a33b4a8-66f4-4d39-f385-57d60ec4ce47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3350000, 16) 3350000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(pd.DataFrame(new_train[:5,:]))"
      ],
      "metadata": {
        "id": "qlhf32QXHgq7",
        "outputId": "a39fcbd4-7d95-499b-979a-68de33790d45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0           1           2           3         4           5   \\\n",
            "0 -174.065872  191.449799 -242.940063  354.925110  0.198780  258.750763   \n",
            "1  -96.874695  106.657539 -134.528931  197.125824  0.110403  144.085175   \n",
            "2  -69.979179   77.745834  -98.210052  143.480713  0.080358  104.601624   \n",
            "3  -57.844669   80.805115  -84.903137  130.705902  0.073204   99.375412   \n",
            "4  -61.115868   67.329201  -85.046448  124.504166  0.069730   90.930580   \n",
            "\n",
            "         6         7         8             9         10        11        12  \\\n",
            "0  0.197174 -0.837500 -0.013387  0.000000e+00  2.308670  0.030141  0.000000   \n",
            "1  0.109796 -0.833690 -0.009577  3.110584e-03  2.308166  0.029637 -0.002257   \n",
            "2  0.079709 -0.837500 -0.013387 -2.381772e-03  2.303668  0.025138 -0.004399   \n",
            "3  0.075726 -0.774562  0.049551  1.657324e-14  2.192084 -0.086446 -0.132403   \n",
            "4  0.069291 -0.834869 -0.010755  1.927597e-03  2.307859  0.029329 -0.001967   \n",
            "\n",
            "         13        14            15  \n",
            "0  0.032980 -0.684483  6.123234e-17  \n",
            "1  0.031146 -0.682452  3.110574e-03  \n",
            "2  0.028481 -0.684483 -2.381767e-03  \n",
            "3  0.099640 -0.649574  1.649253e-14  \n",
            "4  0.031239 -0.683082  1.927595e-03  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizziamoooooo\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "new_train=scaler.fit_transform(new_train)\n",
        "\n",
        "print(pd.DataFrame(new_train[:5,:]))\n"
      ],
      "metadata": {
        "id": "7fLBkXWYH5ZU",
        "outputId": "ad6963af-d113-4005-eba3-a2dde52bdf3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0         1         2         3         4         5         6   \\\n",
            "0 -6.883170  7.601083 -6.769922  7.009325  5.828180  7.276984  5.764971   \n",
            "1 -3.831590  4.233427 -3.747967  3.765627  3.099788  3.916055  3.073457   \n",
            "2 -2.768336  3.085154 -2.735580  2.662906  2.172250  2.758764  2.146670   \n",
            "3 -2.288626  3.206658 -2.364651  2.400309  1.951370  2.605580  2.023997   \n",
            "4 -2.417945  2.671441 -2.368645  2.272827  1.844140  2.358056  1.825773   \n",
            "\n",
            "         7         8         9         10        11        12        13  \\\n",
            "0 -1.575534 -0.167330  0.000234  1.816271  0.379917  0.363434 -0.310036   \n",
            "1 -1.568347 -0.120131  0.043292  1.815873  0.373555  0.341383 -0.329458   \n",
            "2 -1.575534 -0.167330 -0.032736  1.812321  0.316792  0.320464 -0.357675   \n",
            "3 -1.456829  0.612327  0.000234  1.724213 -1.091260 -0.929847  0.395762   \n",
            "4 -1.570571 -0.134733  0.026917  1.815630  0.369676  0.344225 -0.328467   \n",
            "\n",
            "         14        15  \n",
            "0 -1.757688  0.000210  \n",
            "1 -1.752462  0.044307  \n",
            "2 -1.757688 -0.033555  \n",
            "3 -1.667831  0.000210  \n",
            "4 -1.754082  0.027537  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2=np.reshape(new_train,(nj,n_p,nf))\n",
        "print(X_train_2.shape)"
      ],
      "metadata": {
        "id": "H9xlaO5tJcWu",
        "outputId": "3183da66-af15-4947-bc14-a0380cc451f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33500, 100, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train_2"
      ],
      "metadata": {
        "id": "VLU-0PLWJqMZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXcGfbzjD0iI"
      },
      "source": [
        "# Building the RNN model\n",
        "\n",
        "A recurrent neural network (RNN) is a type of NN which processes sequential data or time series data. They are commonly used for ordinal or temporal problems, such as natural language processing (NLP). They are distinguished by their “memory” as they take information from prior inputs to influence the current input and output.\n",
        "\n",
        "<img src=\"https://github.com/NoemiTagliavacche/ML_course_Pavia_23/blob/main/neural-networks/figures/rnn1.png?raw=1\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "\n",
        "In this notebook we treat the particles clustered by the jet algorithm as an ordered sequence processed through a type of RNN called [Gated Recurrent Units](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be). GRUs are improved version of standard RNN that solves the solves the vanishing gradient problem. The update and reset gates decide what information should be passed to the output making the model able to keep information from long ago, without washing it through time or remove information which is irrelevant to the prediction. The main ingredients are:\n",
        "\n",
        "- number of hidden units: the size of the hidden state *ht*\n",
        "- gates activation function (typically a sigmoid between 0 and 1 to either let no flow or complete flow of information throughout the gates)\n",
        "- current state activation function (typically a tanh between -1 and 1 to allow for increases and decreases in the state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nu5HtGc1D0iI"
      },
      "outputs": [],
      "source": [
        "# keras imports\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, GRU, Dropout,Masking\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YclrN8e3D0iI"
      },
      "outputs": [],
      "source": [
        "featureArrayLength = (X_train.shape[1],X_train.shape[2])\n",
        "dropoutRate = 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sMUcjAOPD0iJ"
      },
      "outputs": [],
      "source": [
        "####\n",
        "inputList = Input(shape=(featureArrayLength))\n",
        "x= Masking(mask_value=0.0)(inputList) # aggiungo la maschera perchè il mio dataset originare è fatto da 100 particelle fisse mentre GRU\n",
        "# vuole in ingresso data with variable lenghts e questo fa si che io abbia variable dataset\n",
        "x = GRU(units=40, activation=\"tanh\", recurrent_activation='sigmoid')(inputList)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Dense(20, activation='relu')(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Dense(10, activation='relu')(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "x = Dense(5, activation='relu')(x)\n",
        "#\n",
        "output = Dense(5, activation='softmax')(x)\n",
        "####\n",
        "model = Model(inputs=inputList, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rGD8RNkmD0iJ",
        "outputId": "ec6c8df8-9ba0-4b8c-e21d-5759f16362cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 16)]         0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 40)                6960      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                820       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 30        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,075\n",
            "Trainable params: 8,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjOxf94MD0iJ"
      },
      "source": [
        "We now train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nhoWM0pbD0iK"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "n_epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KidzqAFSD0iK",
        "outputId": "b3f7fa9c-2c87-431d-d2ec-af6d6b75e271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "262/262 - 29s - loss: 1.6088 - val_loss: 1.6087 - lr: 0.0010 - 29s/epoch - 109ms/step\n",
            "Epoch 2/200\n",
            "262/262 - 18s - loss: 1.5752 - val_loss: 1.6057 - lr: 0.0010 - 18s/epoch - 70ms/step\n",
            "Epoch 3/200\n",
            "262/262 - 20s - loss: 1.3912 - val_loss: 1.6599 - lr: 0.0010 - 20s/epoch - 75ms/step\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "262/262 - 18s - loss: 1.3332 - val_loss: 1.6836 - lr: 0.0010 - 18s/epoch - 69ms/step\n",
            "Epoch 5/200\n",
            "262/262 - 19s - loss: 1.3079 - val_loss: 1.6927 - lr: 1.0000e-04 - 19s/epoch - 74ms/step\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "262/262 - 23s - loss: 1.3036 - val_loss: 1.7170 - lr: 1.0000e-04 - 23s/epoch - 89ms/step\n",
            "Epoch 7/200\n",
            "262/262 - 18s - loss: 1.3019 - val_loss: 1.7096 - lr: 1.0000e-05 - 18s/epoch - 70ms/step\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "262/262 - 22s - loss: 1.3022 - val_loss: 1.7059 - lr: 1.0000e-05 - 22s/epoch - 84ms/step\n",
            "Epoch 9/200\n"
          ]
        }
      ],
      "source": [
        "# train \n",
        "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=(X_val, y_val),\n",
        "                callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
        "                TerminateOnNaN()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNtPnGxsD0iK"
      },
      "outputs": [],
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.yscale('log')\n",
        "plt.title('Training History')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YLD1FcGD0iL"
      },
      "source": [
        "# Building the ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jprVwV_D0iL"
      },
      "outputs": [],
      "source": [
        "labels = ['gluon', 'quark', 'W', 'Z', 'top']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh6nYDi0D0iL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "predict_val = model.predict(X_val)\n",
        "df = pd.DataFrame()\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        df[label] = y_val[:,i]\n",
        "        df[label + '_pred'] = predict_val[:,i]\n",
        "\n",
        "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
        "\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.000001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3IYqSmMD0iL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}